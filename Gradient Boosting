//IMPORTING LIBRARIES//
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt 
import seaborn as sns

from sklearn.preprocessing import RobustScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, GridSearchCV 
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import recall_score, accuracy_score, f1_score
from sklearn.metrics import confusion_matrix, matthews_corrcoef
from sklearn.metrics import precision_score, auc, roc_auc_score
from sklearn.metrics import roc_curve, precision_recall_curve 
from sklearn.metrics import classification_report

from sklearn.feature_selection import mutual_info_classif
from sklearn.preprocessing import StandardScaler

from sksurv.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis
from sksurv.ensemble import GradientBoostingSurvivalAnalysis
from sksurv.preprocessing import OneHotEncoder

from sksurv.ensemble import RandomSurvivalForest
from sksurv.metrics import (concordance_index_censored,cumulative_dynamic_auc)


//Train and Test Split
from sksurv.datasets import get_x_y
X, y = get_x_y(dataset, attr_labels=['DEATH_EVENT','time'], pos_label=True, survival=True)
X_list = list(X.columns)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state=8)
print(f'training samples: {len(y_train)}')
print(f'validation samples: {len(y_test)}')
